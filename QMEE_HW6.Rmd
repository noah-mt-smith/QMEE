# Noah Smith QMEE homework 6

### Question 1a:

![](hw6_q1a_figure.jpg)

### Question 1b:

My two main response variables (proportion of funds allocated to winner and proportion of coaching hours allocated to winner) are continuous variables on the ratio scale. This means that, if participant A allocates 0.8 of their funds to the winner and participant B allocates 0.1 of their funds to the winner, participant A has allocated 8 times as much. And if participant C allocated 0.4 of their funds to the winner, they allocated half of what participant A allocated and 4 times what participant B allocated. I can therefore take the mean of my response variable and compare it to my null of 0.5, as the mean for continuous ratio variables is a meaningful measure. If my response variables had been nominal (e.g., "all funds to winner" as 1, and "no funds to winner" as 0), then a mean measure would be meaningless. Similarly, if my response variables were ordinal instead of continuous ratio variables, then I also wouldn't be able to compare my mean to my null--in the cases of nominal or ordinal data, it would make more sense to use the median or mode response. In terms of the inferential approach, I have tried several up to this point, including a one-sample t-test, a separate linear model that includes my various predictor variables (which violates several important assumptions), and when we learn permutations I am interested to see if they are appropriate for my data, given their lack of reliance on some assumptions that my lm is probably violating. I had asked Ben if a one-sample permutation test would be feasible, and he seemed to indicate that it would not be, but I am interested to learn more about this next week.

### Question 2a:

For your continuous response variable, and focusing on one (or at most two) predictors ( continuous or factors) you will be using from your dataset for this class, provide what measures of effect you plan to use. Please explain your rationale fully, including any historical precedent in your field (what is typically used in studies similar to yours), and why you do (or do not) agree with the historical precedent.

For both of my continuous response variables (proportion of funds allocated to winner and proportion of coaching hours allocated to the winner), I will be using Cohen's d. Although Nakagawa & Cuthill (2007) note that Hedges' G provides a "correction" to Cohen's d, but that Hedges' G is most useful for investigations with fairly low sample sizes. Underpowered studies/studies with small sample sizes are more prone to generating inflated effect sizes, and Hedges' G remedies that problem. However, since my study is appropriately powered (having 170 individuals, or about 85 observations for the two competitive contexts, and it met the threshold outlined in an a priori power analysis), I feel that using Cohen's d is appropriate here. The historical context of Cohen's d is somewhat dicey, as it has (potentially) contributed to the replication crisis in experimental psychology and sociology. For several decades, underpowered samples in experimental psychology generated deflated p-values and inflated effect sizes, the latter of which were often calculated with Cohen's d. Once the corrected version of Cohen's d came along (Hedge's g), this issue was resolved slightly, but inflated effect sizes have led to a lot of confusion among scientists and the general public. For example, many of the studies in Daniel Kahneman's "Thinking Fast and Slow" do not replicate. For example, "Ego depletion"--the idea that doing more difficult tasks in the present will make it more difficult to do future difficult tasksâ€”does not replicate.

NEED TO FIND AN EXAMPLE THAT ACTUALLY USED COHEN'S D
